# Title: WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off

#### Members' Names : Burhan Maseel & Lakshita Mahajan

#### Emails: burhan.maseel@torontomu.ca & lakshita.mahajan@torontomu.ca

# 1. Introduction

#### Problem Description:
Watermarking has become a very critical tool in nullyfying the misuse of Large Language Models (LLMs), as these models can generate text that mimics human writing. There are a huge amount of risks associated, including pretending to be someone else and the generation of fake news. To combat these threats, the ability to trace the origin of generated text is crucial. As LLMs are increasingly used in academic and professional settings, this raises concerns about cheating, plagiarism, and authenticity. For instance, college students might use LLMs to generate essays, reports, or assignments without proper citation, undermining academic integrity. Similarly, in interviews, candidates may use LLMs to generate responses that appear original, leading to unfair advantages and misrepresentations of their actual abilities.

#### Context of the Problem:
Existing watermarking techniques aim to embed imperceptible signals within the text generated by an LLM, allowing the text's origin to be identified later through a secret key. However, many of these methods face a significant trade-off between detectability and text quality. The current literature reveals that while passive methods for text forensics are versatile, they offer low performance with error rates that rarely dip below 10^-3. Active methods like watermarking, though more effective, typically introduce distortions in the text to achieve higher detectability, which compromises the quality of the generated content.

The rise of LLMs has further exacerbated the issue of plagiarism and cheating in education. As these models can generate human-like text on demand, students might exploit them to bypass the effort required for assignments, ultimately degrading the learning process and academic standards. In interviews, candidates might use LLMs to craft responses that appear intelligent and insightful but lack personal experience or understanding. This creates an unfair scenario where the candidate’s true capabilities are hidden, leading to unjust outcomes in hiring decisions.

The ability to detect such misuse through watermarking is essential, but it must be done without compromising the quality of the generated content. As a result, a reliable and robust watermarking technique is needed to address the growing concerns around cheating, plagiarism, and the overall integrity of systems that rely on generated content.

#### Limitation About other Approaches:

*   **Traditional Supervision (Hand-Labeled Data by Subject Matter Experts (SMEs))**

*   **Semi-supervised Learning (Use of structural assumptions on unlabeled data)**

*	**Transfer Learning (Use of pre-trained models)**

# Background


| Reference |Explanation |  Dataset/Input |Weakness
| --- | --- | --- | --- |
| Test | Test | Test | Test |
| Test | Test | Test | Test |


# 2. Methodology

WaterMax introduces a black-box watermarking strategy that ensures robustness and fluency without accessing the internal workings of the language model.

## Watermark Score Function

WaterMax defines a **scoring function** that evaluates how well a generated chunk aligns with a seeded statistical signature. This function enables the system to rank candidate chunks based on how detectable and consistent their watermark signals are.

The watermark score \( S \) for a chunk is calculated as:

\[
S = \sum_{i=1}^{n} \delta\left( \text{chunk}_i \oplus \text{key}_i \right)
\]

Where:
- \( \delta \) returns 1 if the tokens match and 0 otherwise.
- \( n \) is the number of tokens in the chunk.
- \( \text{chunk}_i \) and \( \text{key}_i \) represent the i-th token in the chunk and the watermark key.

## Exploring the Text Space

Instead of modifying token distributions, WaterMax performs **draft-and-select**:

- Multiple candidate chunks are sampled using the base LLM.
- The scoring function evaluates each candidate chunk.
- The chunk with the best score is selected.
- This process repeats chunk by chunk until the full text is generated.

This allows WaterMax to embed watermarks in a **black-box setting** without sacrificing text quality.

## Detection Strategy

Watermark detection is performed using a **likelihood ratio test (LRT)**:

\[
P_{\text{watermark}} = \frac{\text{score of watermark chunk}}{\text{score of random chunk}}
\]

- This test compares the probability of the text being generated with vs. without the watermark under the known seed.
- If the ratio exceeds a threshold, the text is classified as watermarked.

## Robustness to Adversarial Attacks

WaterMax enhances robustness through **chunk-based watermarking**:

- Watermarks are independently embedded in each chunk.
- Local edits (e.g., paraphrasing) only affect some chunks, leaving others intact.
- This design improves resistance against common attacks compared to continuous watermarking.

## Tuning the Trade-off between Fidelity and Detectability

WaterMax introduces a **tuning knob** that balances watermark strength and fluency:

- More drafts = stronger watermark signal, slightly lower fluency.
- Fewer drafts = higher fluency, slightly weaker watermark.

This trade-off allows adapting the watermarking strategy based on application needs.



# 3. Solution

In this section, we outline the solution provided by **WaterMax** for embedding a watermark into text generated by Large Language Models (LLMs). The approach leverages a detector-first design that maximizes detection power while ensuring high-quality, fluent text generation. Below, we explain the key components of the solution.

## 3.1. Watermark Embedding Strategy

**WaterMax** employs a robust watermark embedding strategy that is based on a **chunk-level selection process**. This process enables embedding watermarks without modifying the core architecture or components of the LLM, ensuring the model's functionality remains intact.

### Key Steps in Watermark Embedding:

- **Chunk Generation**: For each segment of the text, multiple candidate chunks are generated using the LLM.
- **Watermark Score Calculation**: Each candidate chunk is evaluated using the **watermark score function**, which calculates the similarity between the chunk and a pre-defined watermark key.
- **Best Chunk Selection**: The chunk with the highest watermark score is selected, ensuring that the watermark is embedded without sacrificing fluency.
- **Iterative Process**: This chunk-based embedding process is repeated for each text segment, ensuring that the watermark is efficiently embedded in the entire text.

This process guarantees that the watermark is seamlessly embedded without requiring internal model modifications, preserving the LLM's original performance and output quality.

## 3.2. Detection Mechanism

Once the watermark is embedded, it can be detected using a **likelihood ratio test (LRT)**. This test allows for the identification of the watermark in the text without requiring access to the internal parameters of the LLM.

### Likelihood Ratio Test for Watermark Detection:

- **Test Functionality**: The LRT compares the likelihood of the text being generated with or without the watermark under the known seeded key.
- **No Need for Model Access**: Unlike traditional methods, **WaterMax** does not require access to the LLM's internals (such as logits or weights).
- **Detection Formula**: The detection is based on the following formula:
  
  \[
  P_{\text{watermark}} = \frac{\text{score of watermark chunk}}{\text{score of random chunk}}
  \]

  If the ratio exceeds a defined threshold, the text is flagged as watermarked.

## 3.3. Robustness and Scalability

**WaterMax** is designed to be robust against various adversarial attacks such as paraphrasing or text manipulation. The use of independent chunks ensures that partial changes in the text do not affect the entire watermark, making it resilient to local edits.

### Advantages of WaterMax's Robustness:

- **Chunk-Based Design**: The watermark is embedded across multiple independent chunks of text, increasing robustness.
- **Local Impact of Edits**: Any changes or edits to individual chunks affect only those specific chunks, preserving the watermark in the rest of the text.
- **Resiliency to Paraphrasing**: The chunk-based design makes it harder for attackers to remove or alter the watermark without significantly degrading the overall text quality.

In addition, **WaterMax** is highly scalable, able to handle large volumes of text generation without significant loss in performance or detection accuracy. The computational complexity remains manageable thanks to modern GPU parallelization techniques.

## 3.4. Key Benefits of the WaterMax Solution

The **WaterMax** watermarking scheme offers several notable benefits that differentiate it from previous approaches:

- **High Detection Accuracy**: Even on short texts, **WaterMax** achieves near-perfect detection accuracy.
- **Minimal Impact on Text Quality**: Unlike previous methods, **WaterMax** ensures that the watermark embedding process does not degrade the fluency or readability of the text.
- **No Model Modification**: **WaterMax** operates as a black-box approach, ensuring that the LLM’s core functionality remains unchanged, allowing for easy integration with pre-existing models.
- **Scalability**: The solution is highly scalable and can be applied to large datasets or real-time text generation scenarios.

**WaterMax** stands out as a robust, efficient, and scalable solution for watermarking text generated by LLMs, offering high detection rates while maintaining text quality.




# 4. Implementation

#### Install all required libraries




```python
pip install ./requirements.txt
```


### Start: Preprocessing Data

## Step 1: Labelling functions


# 5. Conclusion and Future Direction


**Conclusion**

WaterMax stands out as a new approach to watermarking text generated by large language models (LLMs). Unlike earlier methods, it starts by designing a strong detection system first, and then builds a generation process that makes the watermark easy to spot — without changing anything inside the LLM.

This smart design brings several key benefits:
- **High Quality**: The generated text still reads naturally and fluently.
- **Strong Detection**: The watermark is easy to detect, even in short texts.
- **Robustness**: It holds up well against paraphrasing and small edits.
- **No LLM Changes**: It works with any LLM (even closed ones like ChatGPT) without needing internal access.


**Future Direction**
A key direction for future work is the **distillation of WaterMax** — training or fine-tuning a language model to natively generate watermarked text. This would eliminate the current computational overhead of generating multiple drafts and make the watermarking process faster and more efficient.

If successful, this approach could allow real-time, low-cost watermarking while keeping all the benefits of WaterMax — high fluency, strong detection, and compatibility with any LLM.

**Lessons Learned**

- Learned how to clone and set up a GitHub project locally.
- Understood the overall structure and logic of the WaterMax codebase.
- Gained hands-on experience in running the project and interpreting the output.
- Developed a deeper understanding of how watermarking works in LLMs through practical exploration.
- Realized the importance of detector-first design and chunk-level sampling in watermark robustness.


# References:

[1]: Giboulot, E., & Furon, T. (2024, December 11). WaterMax: Breaking the LLM watermark detectability-robustness-quality trade-off. Advances in Neural Information Processing Systems, 37 (NeurIPS 2024) Main Conference Track, https://openreview.net/forum?id=HjeKHxK2VH.
